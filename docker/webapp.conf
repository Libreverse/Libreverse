server {
    # listen 443 ssl http2 reuseport;  # enable when terminating TLS here
    # listen 443 quic reuseport;        # HTTP/3/QUIC (requires TLS + certs)
    # NOTE: Using cleartext HTTP/2 (h2c) on this port breaks curl/browsers unless they
    # use prior-knowledge/upgrade. Serve standard HTTP/1.1 here for localhost:3000.
    # If you want HTTP/2, terminate TLS on :443 with `listen 443 ssl http2;` instead.
    listen 3000 default_server reuseport backlog=8192;
    server_name libreverse;
    root /home/app/webapp/public;

    # --- TLS configuration (commented until certificates are provisioned) ---
    # ssl_certificate           /etc/nginx/ssl/cert.pem;           # place certs in image/volume
    # ssl_certificate_key       /etc/nginx/ssl/key.pem;            # use ECC (prime256v1) or RSA 2048+
    # ssl_protocols             TLSv1.2 TLSv1.3;
    # ssl_prefer_server_ciphers on;
    # ssl_ciphers               'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256';
    # ssl_ecdh_curve            X25519:prime256v1;
    # ssl_session_timeout       1d;
    # ssl_session_cache         shared:SSL:10m; # ~40k sessions
    # ssl_stapling              on;
    # ssl_stapling_verify       on;

    # HTTP/3/QUIC support
    # add_header Alt-Svc 'h3=":443"; ma=86400';

    # Enable ModSecurity (WAF) with OWASP CRS
    modsecurity on;
    modsecurity_rules_file /etc/modsecurity/main.conf;

    passenger_enabled on;
    passenger_user app;
    # passenger_ruby defined globally; omit here to avoid duplicates
    passenger_app_env production;
    # Keep at least one app process resident to reduce cold-start latency
    passenger_min_instances 1;
    # Proactively reset timed out client connections to free up sockets faster
    reset_timedout_connection on;

    # If proxying to upstreams is introduced later, consider upstream keepalive:
    # upstream backend { server 127.0.0.1:9000; keepalive 32; }

    # Teach Rack::Sendfile (via Rails) how to map filesystem paths to
    # internal NGINX locations for X-Accel-Redirect acceleration.
    # This sets the X-Accel-Mapping environment variable visible to the app.
    # Multiple mappings can be provided by separating with commas.
    # Paths must end with a trailing slash.
    # Provide X-Accel-Mapping as a single value (comma-separated list)
    passenger_env_var X-Accel-Mapping /home/app/webapp/storage/=/_internal/storage/,/home/app/webapp/private/=/_internal/private/;

    # CrowdSec bouncer access check
    access_by_lua_block {
        local cs = require "crowdsec"
        if ngx.var.unix == "1" then
            ngx.log(ngx.DEBUG, "[Crowdsec] Unix socket request ignoring...")
        else
            cs.Allow(ngx.var.remote_addr)
        end
    }

    location /cable {
        passenger_app_group_name libreverse_action_cable;
        passenger_force_max_concurrent_requests_per_process 0;
    # Real-time; ensure no buffering if proxied elsewhere
    # proxy_buffering off;
    }

    # Private, accelerated sendfile locations (internal-only)
    # Files under these paths can be served by returning an
    # X-Accel-Redirect header pointing at these URIs.
    location ^~ /_internal/storage/ {
        internal;
        alias   /home/app/webapp/storage/;
    }

    location ^~ /_internal/private/ {
        internal;
        alias   /home/app/webapp/private/;
    }

    # Cache static assets aggressively (client-side)
    location ~* \.(?:css|js|mjs|json|jpg|jpeg|gif|png|svg|webp|ico|woff2?|ttf|otf|map)$ {
        expires 30d;
        add_header Cache-Control "public, max-age=31536000";
        try_files $uri =404;
    }

    # Upload tuning: allow slower clients to stream large bodies
    client_body_timeout 60s;
    send_timeout 60s;
    # Allow small request bodies in memory; large ones spill to disk per client_body_buffer_size
    # (disk path configured globally via client_body_temp_path)
    # client_body_in_file_only clean;
    # Optional for very large files (enable if serving multi-GB blobs)
    directio 4m;
    sendfile_max_chunk 512k;

    # Basic NGINX status for troubleshooting (bind to localhost)
    location = /nginx_status {
        stub_status;
        allow 127.0.0.1;
        deny all;
    }

    # Proxy native gRPC over HTTP/2 (h2c) behind the same host on /api/grpc
    # Note: clients must use HTTP/2 for this location. If a front reverse proxy
    # terminates TLS, ensure it speaks HTTP/2 to this backend for /api/grpc.
    location /api/grpc {
        # ModSecurity is not gRPC-aware; disable to prevent false positives
        modsecurity off;

        # Note: gRPC works best over HTTP/2, but do not enforce it at this layer in dev.
        # If a pure HTTP/1.1 client hits this location, upstream may still fail
        # (use grpc-web or an HTTP/2-aware client for proper gRPC calls).

        # Remove the /api/grpc prefix so upstream sees /package.Service/Method
        rewrite ^/api/grpc/(.*)$ /$1 break;

        # Forward to local gRPC server (plaintext)
        grpc_pass grpc://127.0.0.1:50051;

        # Common proxy headers
        grpc_set_header Host $host;
        grpc_set_header X-Request-Id $request_id;
        grpc_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        grpc_set_header X-Forwarded-Proto $scheme;
        grpc_set_header X-Forwarded-Host $host;

        # Timeouts tuned for RPCs
        grpc_read_timeout 60s;
        grpc_send_timeout 60s;

        # Optional: increase for large messages/streams
        # client_max_body_size 32m;
    }
}
